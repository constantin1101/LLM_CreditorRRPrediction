{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "# Add a constant to the model (intercept)\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''If executed in Google Colab, uncomment the following lines'''\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#import os\n",
    "#os.chdir('/content/drive/MyDrive/LLM_CreditorRRPrediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTS = ['presentation', 'qna']\n",
    "\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "aggregated = pd.read_csv('transcripts/aggregated_credit_df.csv', delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import system_message.txt as a string\n",
    "for part in PARTS:\n",
    "    with open(f'cot/system_{part}_scores.txt', 'r') as file:\n",
    "        system_message = file.read()\n",
    "\n",
    "    for idx, row in aggregated.iterrows():\n",
    "        try:\n",
    "            if part == 'qna':\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_message},\n",
    "                        {\"role\": \"user\", \"content\": row['QnA']},\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_message},\n",
    "                        {\"role\": \"user\", \"content\": row['presentation']},\n",
    "                    ]\n",
    "                )\n",
    "            # Instantly add the output as a new column entry for the corresponding row\n",
    "            response = completion.choices[0].message.content\n",
    "\n",
    "            print(response)\n",
    "            aggregated.at[idx, f'{part}_response'] = response\n",
    "\n",
    "        except openai.error.OpenAIError as e:\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "            print(\"Waiting for 1 minute before retrying...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    # to csv\n",
    "    aggregated.to_csv(f'cot/reasoning_{part}_response.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "aggregated = pd.read_csv('cot/reasoning_presentation_response.csv', delimiter='|')\n",
    "aggregated_qna = pd.read_csv('cot/reasoning_qna_response.csv', delimiter='|')\n",
    "\n",
    "# merge the two dataframes\n",
    "aggregated = pd.merge(aggregated, aggregated_qna[['call_ID', 'qna_response']], on='call_ID', how='left')\n",
    "\n",
    "# drop duplicates\n",
    "aggregated = aggregated.drop_duplicates(subset='call_ID')\n",
    "\n",
    "# reset the index\n",
    "aggregated = aggregated.reset_index(drop=True)\n",
    "\n",
    "# sort by call_ID\n",
    "aggregated = aggregated.sort_values(by='call_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Process the string and convert to a dictionary\n",
    "def transform_to_dict(response_string):\n",
    "    response_dict = {}\n",
    "    matches = re.findall(r'(\\d+): \\[\\[(.*?)\\]\\]', response_string, re.DOTALL)\n",
    "    for match in matches:\n",
    "        call_id = int(match[0])\n",
    "        values = [float(re.sub(r'[^\\d.-]', '', v)) for v in match[1].split(\"], [\")]\n",
    "        response_dict[call_id] = values\n",
    "    return response_dict\n",
    "\n",
    "# Function to process responses and split into DataFrame\n",
    "def process_responses(responses, part):\n",
    "    data = []\n",
    "    for packet in responses:\n",
    "        # packet to list\n",
    "        # Transform the responses\n",
    "        result_dict = transform_to_dict(packet)\n",
    "        for key in result_dict:\n",
    "            # Extract the JSON structure from the response\n",
    "            row_data = {'call_ID': key}\n",
    "            values = result_dict[key]\n",
    "\n",
    "            if part == 'qna':\n",
    "                if len(values) < 7:\n",
    "                    print(f\"Skipping call_ID {key} due to insufficient data\")\n",
    "                    continue\n",
    "                \n",
    "                # Parse response columns and populate the DataFrame\n",
    "                row_data['analyst_concerns'] = float(values[0]) \n",
    "                row_data['responsiveness'] = float(values[1])\n",
    "                row_data['confidence'] = float(values[2])\n",
    "                row_data['evasiveness'] = float(values[3])\n",
    "                row_data['depth'] = float(values[4])\n",
    "                row_data['analyst_satisfaction'] = float(values[5])\n",
    "                row_data['language_accessibility_qna'] = float(values[6])\n",
    "                data.append(row_data)\n",
    "\n",
    "            else:\n",
    "                if len(values) < 13:\n",
    "                    print(f\"Skipping call_ID {key} due to insufficient data\")\n",
    "                    continue\n",
    "\n",
    "                # Logic to parse and assign values to each column\n",
    "                if float(values[0]) >= 0:\n",
    "                    row_data['positive_sentiment'] = float(values[0])\n",
    "                    row_data['negative_sentiment'] = 0\n",
    "                else:\n",
    "                    row_data['positive_sentiment'] = 0\n",
    "                    row_data['negative_sentiment'] = -1 * float(values[0])\n",
    "\n",
    "                row_data['uncertainty'] = float(values[1])\n",
    "\n",
    "                if float(values[2]) >= 0:\n",
    "                    row_data['optimistic'] = float(values[2])\n",
    "                    row_data['pessimistic'] = 0\n",
    "                else:\n",
    "                    row_data['optimistic'] = 0\n",
    "                    row_data['pessimistic'] = -1 * float(values[2])\n",
    "\n",
    "                row_data['vagueness'] = float(values[3])\n",
    "                row_data['language_accessibility_presentation'] = float(values[4])\n",
    "                row_data['liquidity_position'] = float(values[5])\n",
    "                row_data['debt_leverage_stress'] = float(values[6])\n",
    "                row_data['operational_trends'] = float(values[7])\n",
    "                row_data['industry_positioning'] = float(values[8])\n",
    "                row_data['asset_quality'] = float(values[9])\n",
    "                row_data['recovery_strategies'] = float(values[10])\n",
    "                row_data['legal_issues'] = float(values[11])\n",
    "                row_data['macroeconomic'] = float(values[12])\n",
    "                data.append(row_data)\n",
    "            \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in PARTS:\n",
    "    # import system_message.txt as a string\n",
    "    with open(f'cot/{part}_compare_scores.txt', 'r') as file:\n",
    "        compare_message = file.read()\n",
    "\n",
    "    # Initialize variables\n",
    "    content = \"\"\n",
    "    batch_indices = []\n",
    "    aggregated['adjusted_scores'] = None  # Initialize with None\n",
    "    counter = 0\n",
    "\n",
    "    all_responses = []\n",
    "\n",
    "    # Iterate over rows in batches of 20\n",
    "    for idx, row in aggregated.iterrows():\n",
    "        # Skip rows with no content in the source column\n",
    "        if pd.isna(row[part + \"_response\"]) or row[part + \"_response\"] == '':\n",
    "            'missing'\n",
    "            continue\n",
    "\n",
    "        content += f'Call No. {idx}: {row[part + \"_response\"]}'\n",
    "        batch_indices.append(idx)  # Keep track of row indices for this batch\n",
    "        counter += 1\n",
    "\n",
    "        if counter == 20:\n",
    "            try:\n",
    "                # Call the API with the batched content\n",
    "                completion = client.chat.completions.create(\n",
    "                    model=\"gpt-4o-mini\",\n",
    "                    temperature=0,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": compare_message},\n",
    "                        {\"role\": \"user\", \"content\": content},\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                # Parse the response\n",
    "                response = completion.choices[0].message.content\n",
    "                print(response)\n",
    "\n",
    "                all_responses.append(response)\n",
    "                \n",
    "                # Reset variables for the next batch\n",
    "                counter = 0\n",
    "                content = \"\"\n",
    "                batch_indices = []\n",
    "                print('done')\n",
    "\n",
    "            except openai.error.OpenAIError as e:\n",
    "                print(f\"An exception occurred: {e}\")\n",
    "                print(\"Waiting for 1 minute before retrying...\")\n",
    "                time.sleep(60)\n",
    "\n",
    "    # Handle any remaining rows if the last batch has fewer than 20 rows\n",
    "    if counter > 0:\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                temperature=0,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": compare_message},\n",
    "                    {\"role\": \"user\", \"content\": content},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response = completion.choices[0].message.content\n",
    "            response_json = response\n",
    "\n",
    "            all_responses.append(response)\n",
    "\n",
    "        except openai.error.OpenAIError as e:\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "            print(\"Waiting for 1 minute before retrying...\")\n",
    "            time.sleep(60)\n",
    "\n",
    "    # replace all ; with ,\n",
    "    all_responses = [x.replace(';', ',') for x in all_responses]\n",
    "\n",
    "    # replace all ' with \"\"\n",
    "    all_responses = [x.replace(\"'\", '') for x in all_responses]\n",
    "\n",
    "    # Process the responses\n",
    "    if part == 'presentation':\n",
    "        presentation_df = process_responses(all_responses, part)\n",
    "    elif part == 'qna':\n",
    "        qna_df = process_responses(all_responses, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two dataframes\n",
    "merged_df = pd.merge(presentation_df, qna_df, on='call_ID', how='left')\n",
    "\n",
    "bond_level = pd.read_csv('transcripts/credit_df.csv', delimiter='|')\n",
    "\n",
    "presentation_labels = ['negative_sentiment', 'positive_sentiment', 'uncertainty', 'optimistic', 'pessimistic', 'vagueness', 'language_accessibility_presentation',\n",
    "              'liquidity_position', 'debt_leverage_stress', 'operational_trends', 'industry_positioning', 'asset_quality', 'recovery_strategies', 'legal_issues','macroeconomic']\n",
    "\n",
    "qna_labels = ['analyst_concerns', 'responsiveness', 'confidence', 'evasiveness', 'depth', 'analyst_satisfaction', 'language_accessibility_qna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename language_accessibility columns\n",
    "merged_df = merged_df.rename(columns={'language_accessibility_x': 'language_accessibility_presentation', 'language_accessibility_y': 'language_accessibility_qna'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = [\n",
    "        'admiration', \n",
    "        #'amusement', \n",
    "        'anger', \n",
    "        'annoyance', \n",
    "        'approval', \n",
    "        'caring', \n",
    "        'confusion', \n",
    "        'curiosity', \n",
    "        'desire',\n",
    "        'disappointment', \n",
    "        'disapproval', \n",
    "        #'disgust', \n",
    "        'embarrassment', \n",
    "        'excitement', \n",
    "        'fear', \n",
    "        #'gratitude', \n",
    "        #'grief',\n",
    "        'joy', \n",
    "        #'love', \n",
    "        'nervousness', \n",
    "        'optimism', \n",
    "        'pride', \n",
    "        'realization', \n",
    "        'relief', \n",
    "        'remorse', \n",
    "        'sadness', \n",
    "        'surprise'\n",
    "    ]\n",
    "\n",
    "analyst_emotions = []\n",
    "for i in emotions:\n",
    "    analyst_emotions.append(i + '_analysts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add GoEmotions labels to the llm_output\n",
    "emotions_presentation = pd.read_csv(f'goemotions/presentation_summary_final.csv', delimiter='|')\n",
    "emotions_qna = pd.read_csv(f'goemotions/qna_summary_final.csv', delimiter='|')\n",
    "emotions_analysts = pd.read_csv(f'goemotions/analysts_summary_final.csv', delimiter='|')\n",
    "\n",
    "emotions_presentation = emotions_presentation[[\"call_ID\"] + emotions]\n",
    "emotions_presentation.drop_duplicates(keep='first', inplace=True)\n",
    "emotions_qna = emotions_qna[[\"call_ID\"] + emotions]\n",
    "emotions_qna.drop_duplicates(keep='first', inplace=True)\n",
    "emotions_analysts = emotions_analysts[[\"call_ID\"] + emotions]\n",
    "emotions_analysts.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge output_df with transcripts on 'transcript_number' and index\n",
    "bond_level = pd.merge(bond_level,\n",
    "                          merged_df[presentation_labels + qna_labels + ['call_ID']],\n",
    "                          on=['call_ID'],\n",
    "                          how='left')\n",
    "\n",
    "llm_output = bond_level.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_output = pd.merge(llm_output, emotions_presentation, on='call_ID', how='left')\n",
    "llm_output = pd.merge(llm_output, emotions_qna, on='call_ID', how='left')\n",
    "\n",
    "for emotion in emotions:\n",
    "    llm_output[emotion] = llm_output[f'{emotion}_x'] + llm_output[f'{emotion}_y']\n",
    "    llm_output.drop([f'{emotion}_x', f'{emotion}_y'], axis=1, inplace=True)\n",
    "    scaler = MinMaxScaler()\n",
    "    llm_output[emotion] = scaler.fit_transform(llm_output[[emotion]])\n",
    "\n",
    "llm_output = pd.merge(llm_output, emotions_analysts, on='call_ID', how='left')\n",
    "\n",
    "# rename emotions_x to emotions and emotions_y to emotions_analysts\n",
    "for emotion in emotions:\n",
    "    llm_output.rename(columns={f'{emotion}_x': f'{emotion}', f'{emotion}_y': f'{emotion}_analysts'}, inplace=True)\n",
    "\n",
    "llm_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace #DIV/0! & Nan with 0\n",
    "# Replace '#DIV/0!' with NaN\n",
    "llm_output.replace('#DIV/0!', np.nan, inplace=True)\n",
    "llm_output = llm_output.fillna(0)\n",
    "\n",
    "# make sure all values are numeric except for the Date column\n",
    "checkpoint = llm_output.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of selected supporting features\n",
    "supporting_features_1 = [\n",
    "    'CBOE DJIA Volatility Index',\n",
    "    'NASDAQ 100 Index return',\n",
    "    'Manufacturers inventories to sales ratio',\n",
    "    '30 year conventional mortgage rate',\n",
    "    'Communication Services', \n",
    "    'Consumer Discretionary', \n",
    "    'Senior secured',  \n",
    "    'Time to maturity',  \n",
    "    'Equity value',\n",
    "    'CDS availability',\n",
    "    'ActIndustryDistress1',\n",
    "    'ActIndustryDistress2',\n",
    "    'Offering amount',\n",
    "    'Volume',\n",
    "    'Industrials','Consumer Staples','Financials','Energy','Health Care','Utilities','Information Technology','Real Estate'\n",
    "]\n",
    "\n",
    "supporting_features_2 = [\n",
    "    'Default barrier',\n",
    "    'LTDIssuance2',\n",
    "    'Intangibility',\n",
    "    'Receivables1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the columns are in datetime format\n",
    "checkpoint['Date'] = pd.to_datetime(checkpoint['Date'])\n",
    "checkpoint['Ddate'] = pd.to_datetime(checkpoint['Ddate'])\n",
    "checkpoint['t_delta'] = checkpoint['Ddate'] - checkpoint['Date']\n",
    "\n",
    "# drop all with t_delta > 180\n",
    "llm_output = checkpoint[checkpoint['t_delta'] <= pd.Timedelta('180 days')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "llm_output[supporting_features_1 + supporting_features_2 + qna_labels + presentation_labels] = scaler.fit_transform(llm_output[supporting_features_1 + supporting_features_2 + qna_labels + presentation_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv\n",
    "llm_output.to_csv('transcripts/cot_llm_output_final.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BOND LEVEL'''\n",
    "# Select the supporting features, nlp_lables, and RR from final_df\n",
    "final_df = llm_output[['RR']\n",
    "                    + supporting_features_1\n",
    "                    + supporting_features_2\n",
    "                    + qna_labels\n",
    "                    + presentation_labels\n",
    "                    + emotions\n",
    "                    + analyst_emotions\n",
    "                    ]\n",
    "\n",
    "# In-Sample-Regression\n",
    "y, y = final_df['RR'], final_df['RR']\n",
    "X, X = final_df.drop(columns=['RR']), final_df.drop(columns=['RR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM features QnA\n",
    "\n",
    "X_train = sm.add_constant(X)\n",
    "X_test = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X_train).fit()\n",
    "\n",
    "# Print the summary of the model which includes p-values and significance levels\n",
    "print(model.summary())\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute and print evaluation metrics\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {np.sqrt(mse)}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# other metric\n",
    "# Calculate the residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Plot the residuals\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(y, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Recovery Rate')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select significant features\n",
    "model.significance = model.pvalues[model.pvalues < 0.05].index\n",
    "\n",
    "# build a graph to show the importance of each feature\n",
    "importances = model.params[1:]\n",
    "importances = importances.sort_values()\n",
    "\n",
    "# Sort the importance values based on absolute values, not just positive or negative\n",
    "top_10_importances = importances.abs().sort_values(ascending=False).head(10)\n",
    "\n",
    "# reduce importances to only the top 10\n",
    "importances = importances[top_10_importances.index]\n",
    "importances = importances.sort_values()\n",
    "\n",
    "# color significant features 0/150/130 and others in grey\n",
    "colors = ['#009682' if feature in model.significance else 'grey' for feature in importances.index]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(importances.index, importances.values, color=colors)\n",
    "# Create a custom legend\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, color='#009682'), plt.Rectangle((0, 0), 1, 1, color='grey')]\n",
    "labels = ['Significant', 'Not Significant']\n",
    "plt.legend(handles, labels)\n",
    "plt.xlabel('Impact')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Features Impact on Recovery Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss",
   "language": "python",
   "name": "aiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
