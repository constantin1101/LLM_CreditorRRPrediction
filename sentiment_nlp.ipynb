{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, Pattern\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "from presidio_anonymizer.entities import OperatorConfig\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from source.models import *\n",
    "from source.preprocessing import *\n",
    "from source.variables import *\n",
    "from source.helpers import *\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = pd.read_csv('transcripts/transcripts.csv', delimiter='|')\n",
    "qna =  pd.read_csv('transcripts/QnA.csv', delimiter='|')\n",
    "\n",
    "# Merge the two dataframes\n",
    "df = pd.merge(transcript, qna[['transcript','filename']], on='filename')\n",
    "\n",
    "# rename transcript_x to presentation and transcript_y to QnA\n",
    "df = df.rename(columns={'transcript_x': 'presentation', 'transcript_y': 'QnA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RR_CompanyName</th>\n",
       "      <th>Transcript_Mapping</th>\n",
       "      <th>AllNames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-800-FLOWERS.COM, Inc.</td>\n",
       "      <td>1-800-Flowers.com Inc.</td>\n",
       "      <td>1-800-Flowers.com Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>3M Company, 3M Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>3M Co.</td>\n",
       "      <td>3M Company, 3M Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.M. Castle &amp; Co.</td>\n",
       "      <td>A. M. Castle  Co.</td>\n",
       "      <td>A. M. Castle  Co., A.M. Castle  Co., AM Castle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.M. Castle &amp; Co.</td>\n",
       "      <td>A.M. Castle  Co.</td>\n",
       "      <td>A. M. Castle  Co., A.M. Castle  Co., AM Castle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RR_CompanyName      Transcript_Mapping  \\\n",
       "0  1-800-FLOWERS.COM, Inc.  1-800-Flowers.com Inc.   \n",
       "1               3M Company              3M Company   \n",
       "2               3M Company                  3M Co.   \n",
       "3        A.M. Castle & Co.       A. M. Castle  Co.   \n",
       "4        A.M. Castle & Co.        A.M. Castle  Co.   \n",
       "\n",
       "                                            AllNames  \n",
       "0                             1-800-Flowers.com Inc.  \n",
       "1                                 3M Company, 3M Co.  \n",
       "2                                 3M Company, 3M Co.  \n",
       "3  A. M. Castle  Co., A.M. Castle  Co., AM Castle...  \n",
       "4  A. M. Castle  Co., A.M. Castle  Co., AM Castle...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = pd.read_csv('data/mapping.csv')\n",
    "\n",
    "# create a new column 'AllNames' that concatenates all versions of 'Company' for a 'CompanyName'\n",
    "mapping['AllNames'] = mapping.groupby('RR_CompanyName')['Transcript_Mapping'].transform(lambda x: ', '.join(x))\n",
    "mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RR</th>\n",
       "      <th>ActIndustryDistress1</th>\n",
       "      <th>ActIndustryDistress2</th>\n",
       "      <th>Senior secured</th>\n",
       "      <th>Senior unsecured</th>\n",
       "      <th>Senior subordinated</th>\n",
       "      <th>Subordinated \\&amp; Junior</th>\n",
       "      <th>Equity value</th>\n",
       "      <th>Default barrier</th>\n",
       "      <th>Net income margin</th>\n",
       "      <th>...</th>\n",
       "      <th>Russell 2000 Price Index return</th>\n",
       "      <th>Russell 2000 Vol 1m</th>\n",
       "      <th>Wilshire US Small-Cap Price Index</th>\n",
       "      <th>Wilshire Small Cap Vol</th>\n",
       "      <th>Ddate</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>LTDIssuance2</th>\n",
       "      <th>Intangibility</th>\n",
       "      <th>Receivables1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.28712</td>\n",
       "      <td>0.258205</td>\n",
       "      <td>-0.776257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01903</td>\n",
       "      <td>21.04</td>\n",
       "      <td>3056.03</td>\n",
       "      <td>808.357714</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>Bethlehem Steel Corp.</td>\n",
       "      <td>087509AL9</td>\n",
       "      <td>0.467834468</td>\n",
       "      <td>0.058009127</td>\n",
       "      <td>0.029416454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.553472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-135.21500</td>\n",
       "      <td>1.269706</td>\n",
       "      <td>-0.564199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01903</td>\n",
       "      <td>21.04</td>\n",
       "      <td>3137.10</td>\n",
       "      <td>974.749210</td>\n",
       "      <td>2004-05-01</td>\n",
       "      <td>T-Mobile US, Inc.</td>\n",
       "      <td>45071TAD7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200428895</td>\n",
       "      <td>0.032214499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.315958</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-366.57500</td>\n",
       "      <td>1.081883</td>\n",
       "      <td>-0.671751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01903</td>\n",
       "      <td>21.05</td>\n",
       "      <td>3178.04</td>\n",
       "      <td>825.987663</td>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>RCN Corporation</td>\n",
       "      <td>749361AC5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005146611</td>\n",
       "      <td>0.032214499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54.798870</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-366.57500</td>\n",
       "      <td>1.081883</td>\n",
       "      <td>-0.671751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01903</td>\n",
       "      <td>21.05</td>\n",
       "      <td>3178.04</td>\n",
       "      <td>825.987663</td>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>RCN Corporation</td>\n",
       "      <td>749361AD3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005146611</td>\n",
       "      <td>0.029416454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56.666288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-366.57500</td>\n",
       "      <td>1.081883</td>\n",
       "      <td>-0.671751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01903</td>\n",
       "      <td>21.05</td>\n",
       "      <td>3178.04</td>\n",
       "      <td>825.987663</td>\n",
       "      <td>2004-01-15</td>\n",
       "      <td>RCN Corporation</td>\n",
       "      <td>749361AG6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005146611</td>\n",
       "      <td>0.029416454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RR  ActIndustryDistress1  ActIndustryDistress2  Senior secured  \\\n",
       "0   0.189010                     0                     0               0   \n",
       "1  20.553472                     0                     1               0   \n",
       "2  54.315958                     0                     1               0   \n",
       "3  54.798870                     0                     1               0   \n",
       "4  56.666288                     0                     1               0   \n",
       "\n",
       "   Senior unsecured  Senior subordinated  Subordinated \\& Junior  \\\n",
       "0                 1                    0                       0   \n",
       "1                 1                    0                       0   \n",
       "2                 1                    0                       0   \n",
       "3                 1                    0                       0   \n",
       "4                 1                    0                       0   \n",
       "\n",
       "   Equity value  Default barrier  Net income margin  ...  \\\n",
       "0       1.28712         0.258205          -0.776257  ...   \n",
       "1    -135.21500         1.269706          -0.564199  ...   \n",
       "2    -366.57500         1.081883          -0.671751  ...   \n",
       "3    -366.57500         1.081883          -0.671751  ...   \n",
       "4    -366.57500         1.081883          -0.671751  ...   \n",
       "\n",
       "   Russell 2000 Price Index return  Russell 2000 Vol 1m  \\\n",
       "0                          0.01903                21.04   \n",
       "1                          0.01903                21.04   \n",
       "2                          0.01903                21.05   \n",
       "3                          0.01903                21.05   \n",
       "4                          0.01903                21.05   \n",
       "\n",
       "   Wilshire US Small-Cap Price Index  Wilshire Small Cap Vol      Ddate  \\\n",
       "0                            3056.03              808.357714 2004-01-01   \n",
       "1                            3137.10              974.749210 2004-05-01   \n",
       "2                            3178.04              825.987663 2004-01-15   \n",
       "3                            3178.04              825.987663 2004-01-15   \n",
       "4                            3178.04              825.987663 2004-01-15   \n",
       "\n",
       "             CompanyName      CUSIP  LTDIssuance2  Intangibility  Receivables1  \n",
       "0  Bethlehem Steel Corp.  087509AL9   0.467834468    0.058009127   0.029416454  \n",
       "1      T-Mobile US, Inc.  45071TAD7             0    0.200428895   0.032214499  \n",
       "2        RCN Corporation  749361AC5             0    0.005146611   0.032214499  \n",
       "3        RCN Corporation  749361AD3             0    0.005146611   0.029416454  \n",
       "4        RCN Corporation  749361AG6             0    0.005146611   0.029416454  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load recovery rates\n",
    "rr = pd.read_csv('data/RR_Bonds.csv')\n",
    "rr = rr[['Ddate', 'RR', 'CompanyName', 'CUSIP', 'LTDIssuance2', 'Intangibility', 'Receivables1']]\n",
    "\n",
    "preprocessed_df = pd.read_csv('data/preprocessed_bond_data.csv')\n",
    "\n",
    "# Add rr columns to preprocessed_df on index\n",
    "preprocessed_df['RR'] = rr['RR']\n",
    "preprocessed_df['Ddate'] = rr['Ddate']\n",
    "preprocessed_df['CompanyName'] = rr['CompanyName']\n",
    "preprocessed_df['CUSIP'] = rr['CUSIP']\n",
    "preprocessed_df['LTDIssuance2'] = rr['LTDIssuance2']\n",
    "preprocessed_df['Intangibility'] = rr['Intangibility']\n",
    "preprocessed_df['Receivables1'] = rr['Receivables1']\n",
    "\n",
    "rr = preprocessed_df\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "rr['Ddate'] = pd.to_datetime(rr['Ddate'], errors='coerce')\n",
    "rr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge rr with mapping on CompanyName and RR_CompanyName\n",
    "rr = rr.merge(mapping, left_on='CompanyName', right_on='RR_CompanyName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ally Financial Inc.               10317\n",
      "CIT Group Inc.                    10185\n",
      "Lehman Brothers Holdings, Inc.     2853\n",
      "Charter Communications, Inc.       2144\n",
      "Sempra Energy                      1147\n",
      "                                  ...  \n",
      "Frontier Group Holdings, Inc.         1\n",
      "Dayton Superior Corporation           1\n",
      "Franklin Bank Corp.                   1\n",
      "Kellwood Company, LLC                 1\n",
      "Turning Point Brands, Inc.            1\n",
      "Name: CompanyName, Length: 210, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# join with df on Company and Transcripts_Mapping\n",
    "merged_df = rr.merge(df, left_on='Transcript_Mapping', right_on='Company')\n",
    "print(merged_df['CompanyName'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lehman Brothers Holdings, Inc.      317\n",
      "CIT Group Inc.                      291\n",
      "Charter Communications, Inc.         28\n",
      "Ford Motor Company                   19\n",
      "iStar Inc.                           17\n",
      "                                   ... \n",
      "Centrus Energy Corp.                  1\n",
      "Education Management Corporation      1\n",
      "Venoco, Inc.                          1\n",
      "Exelon Corporation                    1\n",
      "Kellwood Company, LLC                 1\n",
      "Name: CompanyName, Length: 159, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensure the columns are in datetime format\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'])\n",
    "merged_df['Ddate'] = pd.to_datetime(merged_df['Ddate'])\n",
    "\n",
    "# Compute the difference in days\n",
    "merged_df['diff'] = (merged_df['Ddate'] - merged_df['Date']).dt.days\n",
    "\n",
    "merged_df = merged_df[merged_df['Ddate']>merged_df['Date']]\n",
    "merged_df = merged_df.sort_values(by='Date').groupby(['CUSIP']).tail(1)\n",
    "\n",
    "print(merged_df['CompanyName'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Keywords for each credit factor\n",
    "credit_keywords = {\n",
    "    'Profitability': ['revenue', 'cost', 'profit', 'earnings', 'margins', 'performance', 'income', 'loss', 'decline', 'decrease', 'outlook', 'guidance'],\n",
    "    'Liquidity': ['cash', 'liquidity', 'credit', 'flow', 'operations', 'expenditures', 'free cash', 'working capital', 'insolvency', 'crunch', 'flexibility', 'funding'],\n",
    "    'Leverage': ['debt', 'leverage', 'refinancing', 'reduction', 'interest', 'coverage', 'repayments', 'compliance', 'rating', 'default', 'restructuring'],\n",
    "    'Operating': ['sales', 'market share', 'efficiency', 'cost', 'position', 'conditions', 'production', 'challenges', 'decline', 'improvement'],\n",
    "    'Market': ['stock', 'market', 'investor', 'volatility', 'shareholder', 'confidence', 'buybacks', 'dilution', 'perception'],\n",
    "    'Management': ['management', 'strategic', 'restructuring', 'strategy', 'adaptability', 'leadership', 'initiatives', 'governance', 'organizational', 'CEO', 'board']\n",
    "}\n",
    "\n",
    "# Function to identify sections with potential bankruptcy indicators\n",
    "def identify_bankruptcy_indicators(transcript, keywords):\n",
    "    sentences = nltk.sent_tokenize(transcript)\n",
    "    indicator_sentences = []\n",
    "    for sentence in sentences:\n",
    "        for key in keywords:\n",
    "            if any(re.search(r'\\b' + re.escape(word) + r'\\b', sentence, re.IGNORECASE) for word in keywords[key]):\n",
    "                indicator_sentences.append(sentence)\n",
    "                break\n",
    "\n",
    "    return ' '.join(indicator_sentences)\n",
    "\n",
    "# Function to clean text by stemming and replacing numbers with magnitude tokens\n",
    "def clean_text(text):\n",
    "    # Replace numbers with tokens\n",
    "    text = re.sub(r'\\b\\d+(\\.\\d+)?\\s?(billion|bln)\\b', 'bln', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b\\d+(\\.\\d+)?\\s?(million|mln)\\b', 'mln', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\b\\d{1,3}(,\\d{3})*(\\.\\d+)?\\b', 'num', text)  # Replace remaining numbers with 'num'\n",
    "    \n",
    "    # Remove non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize, stem, and rejoin\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words if len(word) > 1]  # Remove single characters that might be noise\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Transform transcript to lowercase\n",
    "merged_df['presentation'] = merged_df['presentation'].str.lower()\n",
    "merged_df['QnA'] = merged_df['QnA'].str.lower()\n",
    "\n",
    "# Apply function to identify bankruptcy indicators\n",
    "merged_df['presentation_cleaned'] = merged_df['presentation'].apply(lambda x: identify_bankruptcy_indicators(x, credit_keywords))\n",
    "merged_df['QnA_cleaned'] = merged_df['QnA'].apply(lambda x: identify_bankruptcy_indicators(x, credit_keywords))\n",
    "\n",
    "# Apply function to clean text\n",
    "merged_df['presentation'] = merged_df['presentation'].apply(clean_text)\n",
    "merged_df['QnA'] = merged_df['QnA'].apply(clean_text)\n",
    "\n",
    "merged_df['presentation_cleaned'] = merged_df['presentation_cleaned'].apply(clean_text)\n",
    "merged_df['QnA_cleaned'] = merged_df['QnA_cleaned'].apply(clean_text)\n",
    "\n",
    "# reset index\n",
    "merged_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>StrongModal</th>\n",
       "      <th>WeakModal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ABANDONED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABANDONING</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ABANDONMENTS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Negative  Positive  Uncertainty  Litigious  StrongModal  \\\n",
       "9        ABANDON         1         0            0          0            0   \n",
       "10     ABANDONED         1         0            0          0            0   \n",
       "11    ABANDONING         1         0            0          0            0   \n",
       "12   ABANDONMENT         1         0            0          0            0   \n",
       "13  ABANDONMENTS         1         0            0          0            0   \n",
       "\n",
       "    WeakModal  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "12          0  \n",
       "13          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = pd.read_csv('data/sentiment.csv')\n",
    "\n",
    "# drop all columns except Word, Negative, Positive, Uncertainty, Litigious, Strong_Modal, Weak_Modal\n",
    "sentiment = sentiment[['Word', 'Negative', 'Positive', 'Uncertainty', 'Litigious', 'StrongModal', 'WeakModal']]\n",
    "\n",
    "# change any number in Negative, Positive, Uncertainty, Litigious, Strong_Modal, Weak_Modal to 1\n",
    "sentiment.loc[sentiment['Negative'] != 0, 'Negative'] = 1\n",
    "sentiment.loc[sentiment['Positive'] != 0, 'Positive'] = 1\n",
    "sentiment.loc[sentiment['Uncertainty'] != 0, 'Uncertainty'] = 1\n",
    "sentiment.loc[sentiment['Litigious'] != 0, 'Litigious'] = 1\n",
    "sentiment.loc[sentiment['StrongModal'] != 0, 'StrongModal'] = 1\n",
    "sentiment.loc[sentiment['WeakModal'] != 0, 'WeakModal'] = 1\n",
    "\n",
    "# drop all rows where all columns are 0\n",
    "sentiment = sentiment[(sentiment[['Negative', 'Positive', 'Uncertainty', 'Litigious', 'StrongModal', 'WeakModal']] != 0).any(axis=1)]\n",
    "\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all words in Word column lowercase and stem them\n",
    "sentiment['Word'] = sentiment['Word'].str.lower()\n",
    "sentiment['Word'] = sentiment['Word'].apply(lambda x: stemmer.stem(x))\n",
    "\n",
    "# drop duplicates\n",
    "sentiment.drop_duplicates(subset='Word', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in lower case\n",
    "financial_lexicon = sentiment['Word'].tolist()\n",
    "\n",
    "def filter_tokens_by_lexicon(text, lexicon):\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word in lexicon]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "filtered_presentation = [filter_tokens_by_lexicon(transcript, financial_lexicon) for transcript in merged_df['presentation']]\n",
    "filtered_presentation_cleaned = [filter_tokens_by_lexicon(transcript, financial_lexicon) for transcript in merged_df['presentation_cleaned']]\n",
    "filtered_qna = [filter_tokens_by_lexicon(transcript, financial_lexicon) for transcript in merged_df['QnA']]\n",
    "filtered_qna_cleaned = [filter_tokens_by_lexicon(transcript, financial_lexicon) for transcript in merged_df['QnA_cleaned']]\n",
    "\n",
    "# Build the DTM\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "presentation_dtm = vectorizer.fit_transform(filtered_presentation)\n",
    "presentation_dtm_df = pd.DataFrame(presentation_dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "presentation_cleaned_dtm = vectorizer.fit_transform(filtered_presentation_cleaned)\n",
    "presentation_cleaned_dtm_df = pd.DataFrame(presentation_cleaned_dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "qna_dtm = vectorizer.fit_transform(filtered_qna)\n",
    "qna_dtm_df = pd.DataFrame(qna_dtm.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "qna_cleaned_dtm = vectorizer.fit_transform(filtered_qna_cleaned)\n",
    "qna_cleaned_dtm_df = pd.DataFrame(qna_cleaned_dtm.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of the dataframes\n",
    "dtm_dict = {\n",
    "    'presentation': presentation_dtm_df,\n",
    "    'presentation_cleaned': presentation_cleaned_dtm_df,\n",
    "    'QnA': qna_dtm_df,\n",
    "    'QnA_cleaned': qna_cleaned_dtm_df\n",
    "}\n",
    "\n",
    "# create a dictionary of dataframes for the 4 types which based on merged_df['RR']\n",
    "dict_rr = {\n",
    "    'presentation': merged_df[['RR','Date', 'presentation']].reset_index(drop=True),\n",
    "    'presentation_cleaned': merged_df[['RR','Date', 'presentation_cleaned']].reset_index(drop=True),\n",
    "    'QnA': merged_df[['RR','Date', 'QnA']].reset_index(drop=True),\n",
    "    'QnA_cleaned': merged_df[['RR','Date', 'QnA_cleaned']].reset_index(drop=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists of categories\n",
    "negative_words = sentiment[sentiment['Negative'] == 1]['Word'].str.lower().tolist()\n",
    "positive_words = sentiment[sentiment['Positive'] == 1]['Word'].str.lower().tolist()\n",
    "uncertainty_words = sentiment[sentiment['Uncertainty'] == 1]['Word'].str.lower().tolist()\n",
    "litigious_words = sentiment[sentiment['Litigious'] == 1]['Word'].str.lower().tolist()\n",
    "strong_modal_words = sentiment[sentiment['StrongModal'] == 1]['Word'].str.lower().tolist()\n",
    "weak_modal_words = sentiment[sentiment['WeakModal'] == 1]['Word'].str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dtm_dict:\n",
    "\n",
    "    # add sentiment scores to the dataframe\n",
    "    dict_rr[key]['NegativeScore'] = 0\n",
    "    dict_rr[key]['PositiveScore'] = 0\n",
    "    dict_rr[key]['UncertaintyScore'] = 0\n",
    "    dict_rr[key]['LitigiousScore'] = 0\n",
    "    dict_rr[key]['StrongModalScore'] = 0\n",
    "    dict_rr[key]['WeakModalScore'] = 0\n",
    "\n",
    "    # iterate of columns in the DTM and add sentiment scores to the dataframe based on categories\n",
    "    for column in dtm_dict[key].columns:\n",
    "        if column in negative_words:\n",
    "            dict_rr[key]['NegativeScore'] += dtm_dict[key][column]\n",
    "        if column in positive_words:\n",
    "            dict_rr[key]['PositiveScore'] += dtm_dict[key][column]\n",
    "        if column in uncertainty_words:\n",
    "            dict_rr[key]['UncertaintyScore'] += dtm_dict[key][column]\n",
    "        if column in litigious_words:\n",
    "            dict_rr[key]['LitigiousScore'] += dtm_dict[key][column]\n",
    "        if column in strong_modal_words:\n",
    "            dict_rr[key]['StrongModalScore'] += dtm_dict[key][column]\n",
    "        if column in weak_modal_words:\n",
    "            dict_rr[key]['WeakModalScore'] += dtm_dict[key][column]\n",
    "    \n",
    "    # compute sentiment = PositiveScore - NegativeScore / Total word count\n",
    "    dict_rr[key]['Sentiment'] = (dict_rr[key]['PositiveScore'] - dict_rr[key]['NegativeScore']) / len(dict_rr[key][key])\n",
    "    dict_rr[key]['OptimismScore'] = (dict_rr[key]['StrongModalScore'] - dict_rr[key]['UncertaintyScore']) / len(dict_rr[key][key])\n",
    "    dict_rr[key]['RiskScore'] = (dict_rr[key]['LitigiousScore'] + dict_rr[key]['WeakModalScore']) / len(dict_rr[key][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_rr:\n",
    "    # transform RR to label 1 if RR > 50 else 0\n",
    "    dict_rr[key]['label'] = dict_rr[key]['RR'].apply(lambda x: 1 if x > 40 else 0)\n",
    "\n",
    "    # if label == 1 and Sentiment > 0 then TP\n",
    "    dict_rr[key]['Prediction'] = dict_rr[key].apply(lambda x: 1 if x['label'] == 1 and x['Sentiment'] > 0 else 0, axis=1)\n",
    "    # if label == 0 and Sentiment < 0 then TN\n",
    "    dict_rr[key]['Prediction'] = dict_rr[key].apply(lambda x: 1 if x['label'] == 0 and x['Sentiment'] < 0 else 0, axis=1)\n",
    "    # if label == 1 and Sentiment < 0 then FN\n",
    "    dict_rr[key]['Prediction'] = dict_rr[key].apply(lambda x: 1 if x['label'] == 1 and x['Sentiment'] < 0 else 0, axis=1)\n",
    "    # if label == 0 and Sentiment > 0 then FP\n",
    "    dict_rr[key]['Prediction'] = dict_rr[key].apply(lambda x: 1 if x['label'] == 0 and x['Sentiment'] > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for presentation: 0.14046511627906977\n",
      "Accuracy for presentation_cleaned: 0.06511627906976744\n",
      "Accuracy for QnA: 0.025116279069767444\n",
      "Accuracy for QnA_cleaned: 0.03255813953488372\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy for each type\n",
    "for key in dict_rr:\n",
    "    accuracy = dict_rr[key]['Prediction'].sum() / len(dict_rr[key])\n",
    "    print(f'Accuracy for {key}: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: presentation\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     RR   R-squared:                       0.415\n",
      "Model:                            OLS   Adj. R-squared:                  0.414\n",
      "Method:                 Least Squares   F-statistic:                     253.7\n",
      "Date:                Thu, 05 Sep 2024   Prob (F-statistic):          2.44e-124\n",
      "Time:                        11:26:44   Log-Likelihood:                -4733.2\n",
      "No. Observations:                1075   AIC:                             9474.\n",
      "Df Residuals:                    1071   BIC:                             9494.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            35.6721      1.779     20.050      0.000      32.181      39.163\n",
      "Sentiment       300.0159     23.216     12.923      0.000     254.461     345.571\n",
      "OptimismScore   572.3731     27.690     20.671      0.000     518.040     626.706\n",
      "RiskScore       490.8940     59.109      8.305      0.000     374.912     606.876\n",
      "==============================================================================\n",
      "Omnibus:                      120.170   Durbin-Watson:                   1.317\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              214.358\n",
      "Skew:                           0.726   Prob(JB):                     2.84e-47\n",
      "Kurtosis:                       4.636   Cond. No.                         98.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Mean Squared Error: 390.77844801658875\n",
      "Root Mean Squared Error: 19.768116956771294\n",
      "R-squared: 0.41537876008332153\n",
      "Score: presentation_cleaned\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     RR   R-squared:                       0.391\n",
      "Model:                            OLS   Adj. R-squared:                  0.389\n",
      "Method:                 Least Squares   F-statistic:                     229.3\n",
      "Date:                Thu, 05 Sep 2024   Prob (F-statistic):          6.67e-115\n",
      "Time:                        11:26:44   Log-Likelihood:                -4755.1\n",
      "No. Observations:                1075   AIC:                             9518.\n",
      "Df Residuals:                    1071   BIC:                             9538.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            44.1537      1.637     26.979      0.000      40.942      47.365\n",
      "Sentiment       406.5108     34.214     11.881      0.000     339.377     473.645\n",
      "OptimismScore   880.2633     42.288     20.816      0.000     797.286     963.240\n",
      "RiskScore       441.5058    101.859      4.334      0.000     241.640     641.371\n",
      "==============================================================================\n",
      "Omnibus:                      105.907   Durbin-Watson:                   1.243\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              188.754\n",
      "Skew:                           0.654   Prob(JB):                     1.03e-41\n",
      "Kurtosis:                       4.582   Cond. No.                         166.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Mean Squared Error: 406.98172625575114\n",
      "Root Mean Squared Error: 20.173788098811563\n",
      "R-squared: 0.39113796414645885\n",
      "Score: QnA\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     RR   R-squared:                       0.073\n",
      "Model:                            OLS   Adj. R-squared:                  0.070\n",
      "Method:                 Least Squares   F-statistic:                     28.11\n",
      "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           1.68e-17\n",
      "Time:                        11:26:44   Log-Likelihood:                -4981.0\n",
      "No. Observations:                1075   AIC:                             9970.\n",
      "Df Residuals:                    1071   BIC:                             9990.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            33.4007      2.287     14.604      0.000      28.913      37.888\n",
      "Sentiment       367.6074     40.536      9.069      0.000     288.069     447.145\n",
      "OptimismScore  -174.7714     45.697     -3.825      0.000    -264.437     -85.106\n",
      "RiskScore       180.3741     65.843      2.739      0.006      51.179     309.569\n",
      "==============================================================================\n",
      "Omnibus:                       68.486   Durbin-Watson:                   0.866\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               80.553\n",
      "Skew:                           0.668   Prob(JB):                     3.22e-18\n",
      "Kurtosis:                       3.123   Cond. No.                         92.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Mean Squared Error: 619.6326699076426\n",
      "Root Mean Squared Error: 24.892421937361632\n",
      "R-squared: 0.07300307472711443\n",
      "Score: QnA_cleaned\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     RR   R-squared:                       0.116\n",
      "Model:                            OLS   Adj. R-squared:                  0.113\n",
      "Method:                 Least Squares   F-statistic:                     46.69\n",
      "Date:                Thu, 05 Sep 2024   Prob (F-statistic):           2.34e-28\n",
      "Time:                        11:26:44   Log-Likelihood:                -4955.7\n",
      "No. Observations:                1075   AIC:                             9919.\n",
      "Df Residuals:                    1071   BIC:                             9939.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            55.3226      2.042     27.086      0.000      51.315      59.330\n",
      "Sentiment       321.3975     70.675      4.548      0.000     182.720     460.075\n",
      "OptimismScore  -664.2325     86.514     -7.678      0.000    -833.988    -494.477\n",
      "RiskScore     -1390.0592    135.539    -10.256      0.000   -1656.012   -1124.107\n",
      "==============================================================================\n",
      "Omnibus:                       80.696   Durbin-Watson:                   0.928\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              101.756\n",
      "Skew:                           0.660   Prob(JB):                     8.02e-23\n",
      "Kurtosis:                       3.726   Cond. No.                         195.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "Mean Squared Error: 591.1247002309883\n",
      "Root Mean Squared Error: 24.313056168054814\n",
      "R-squared: 0.11565221432133577\n"
     ]
    }
   ],
   "source": [
    "for key in dict_rr:\n",
    "    X = dict_rr[key][['Sentiment', 'OptimismScore', 'RiskScore']]\n",
    "    y = dict_rr[key]['RR']\n",
    "\n",
    "    X_train, X_test = X, X\n",
    "    y_train, y_test = y, y\n",
    "\n",
    "    # Fit the model\n",
    "    # Bond data 1 + LLM features\n",
    "\n",
    "    X_train = sm.add_constant(X_train)\n",
    "    X_test = sm.add_constant(X_test)\n",
    "\n",
    "    # Fit the model\n",
    "    model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "    print(f\"Score: {key}\")\n",
    "    # Print the summary of the model which includes p-values and significance levels\n",
    "    print(model.summary())\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute and print evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Root Mean Squared Error: {np.sqrt(mse)}\")\n",
    "    print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss",
   "language": "python",
   "name": "aiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
